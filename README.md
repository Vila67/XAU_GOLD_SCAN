# TRADING BOT XAU/USD

## Description
Bot de trading automatique sp√©cialis√© dans l'analyse multi-timeframes de l'or (XAU/USD).
Utilise l'apprentissage automatique et l'analyse technique.

## Installation
1. Cloner le repository
2. Installer les d√©pendances : `pip install -r requirements.txt`
3. Configurer `.env` avec votre cl√© API Marketstack

## Structure
```
src/
    data_collection/   - Collecte des donn√©es
    preprocessing/     - Traitement des donn√©es
    features/         - Indicateurs techniques
    models/          - Mod√®les de pr√©diction
    visualization/    - Visualisation
tests/              - Tests unitaires
config/             - Configuration
requirements.txt    - D√©pendances
```

## Commandes Principales

### 1. COLLECTE DE DONN√âES
- Historique (une timeframe):
  ```bash
  python src/data_collection/historical_data.py --timeframe 5m
  ```
   
- Toutes timeframes:
  ```bash
  python src/data_collection/historical_data.py --all-timeframes
  ```
   
- Temps r√©el:
  ```bash
  python src/data_collection/marketstack_api.py
  ```

### 2. TRAITEMENT DES DONN√âES
- Basique:
  ```bash
  python src/preprocessing/data_processor.py --input XAUUSD_5m.csv
  ```
   
- Avanc√©:
  ```bash
  python src/preprocessing/data_processor.py --input XAUUSD_5m.csv --max-gap-multiplier 20.0
  ```

### 3. ANALYSE TECHNIQUE
- Ajouter indicateurs:
  ```bash
  python src/features/technical_indicators.py --input XAUUSD_5m.csv
  ```
   
- G√©n√©rer rapport:
  ```bash
  python src/features/technical_indicators.py --report
  ```

### 4. TESTS
- Tous les tests:
  ```bash
  pytest
  ```
   
- Tests sp√©cifiques:
  ```bash
  pytest test_data_processor.py
  pytest test_historical.py
  ```

## Timeframes Disponibles
| Timeframe | Description |
|-----------|-------------|
| 5m        | 5 minutes   |
| 15m       | 15 minutes  |
| 30m       | 30 minutes  |
| 1h        | 1 heure     |
| 4h        | 4 heures    |
| 1d        | 1 jour      |
| 1w        | 1 semaine   |
| 1M        | 1 mois      |

## Indicateurs Techniques

### Moyennes Mobiles
- SMA (Simple Moving Average)
  - P√©riodes : 10, 20, 50, 200
- EMA (Exponential Moving Average)
  - P√©riodes : 12, 26

### Indicateurs de Momentum
- RSI (Relative Strength Index)
  - P√©riode : 14
- MACD (Moving Average Convergence Divergence)
  - EMA rapide : 12
  - EMA lente : 26
  - Signal : 9
- Stochastique
  - %K p√©riode : 14
  - %D p√©riode : 3

### Indicateurs de Volatilit√©
- ATR (Average True Range)
  - P√©riode : 14
- Bandes de Bollinger
  - P√©riode : 20
  - √âcart-type : 2

### Indicateurs de Volume
- Volume SMA (20 p√©riodes)
- Ratio de Volume
- OBV (On-Balance Volume)

Tous les indicateurs sont calcul√©s sur chaque timeframe et utilis√©s comme features pour l'entra√Ænement du mod√®le.

## Configuration du Mod√®le de Trading

### P√©riode couverte
- Donn√©es historiques de 2004 √† 2024 (20 ans)
- Source : Dataset Kaggle "xauusd-gold-price-historical-data-2004-2024"

### √âchantillons
- 3000 √©chantillons cibles pour l'entra√Ænement
- Timeframes analys√©s :
  - 5 minutes (5m)
  - 15 minutes (15m)
  - 30 minutes (30m)
  - 1 heure (1h)
  - 4 heures (4h)
  - 1 jour (1d)
  - 1 semaine (1w)
  - 1 mois (1M)

### Configuration du Backtest
- Capital initial : 100,000 unit√©s
- Seuils de confiance test√©s : 50%, 70%, et 90%
- Validation sur donn√©es historiques de 20 ans

### Param√®tres de Trading
- Objectif par trade : 25 pips
- Horizon de pr√©diction : 12 p√©riodes
- Seuil de confiance minimum : 70%

### Param√®tres de Risque
- Stop loss : 2% du prix d'entr√©e
- Take profit : 3% du prix d'entr√©e
- Taille de position : 2% du capital par trade
- Ratio risque/r√©compense : 1:1.5

### Configuration des Trades
- Capital initial : 100,000 unit√©s
- Gestion de risque conservatrice
- Stops et targets automatiques
- Validation multi-timeframe des signaux

### En termes mon√©taires (sur un capital de 100,000)
- Montant risqu√© par trade : 2,000 (2% du capital)
- Stop loss maximum : 2,000 (2% du capital)
- Gain potentiel : 3,000 (3% du capital)

## Processus d'Analyse pour la Prise de Position

### 1. Analyse Multi-Timeframe
- Analyse simultan√©e sur 8 timeframes :
  - Court terme : 5m, 15m, 30m
  - Moyen terme : 1h, 4h
  - Long terme : 1d, 1w, 1M
- Validation crois√©e des signaux entre timeframes

### 2. Analyse Technique
- **Tendance** :
  - SMA (10, 20, 50, 200)
  - EMA (12, 26)
  - Distance des prix par rapport aux moyennes mobiles
  
- **Momentum** :
  - RSI (14)
  - MACD (12, 26, 9)
  - Stochastique (14, 3)
  - ROC (Rate of Change)
  
- **Volatilit√©** :
  - ATR (14)
  - Bandes de Bollinger (20, 2)
  - Volatilit√© sur 5, 10, 20 p√©riodes
  
- **Volume** :
  - Volume SMA (20)
  - Ratio de Volume
  - OBV (On-Balance Volume)

### 3. Validation du Signal
1. **Pr√©-validation** :
   - V√©rification des conditions de march√©
   - Analyse de la volatilit√© actuelle
   - V√©rification du volume

2. **Analyse ML** :
   - Pr√©diction du mod√®le LSTM/Transformer
   - Score de confiance minimum : 70%
   - Validation sur plusieurs timeframes

3. **Filtres de Trading** :
   - Seuil de confiance : 0.7 (70%)
   - Direction du trade (-1 vente, 0 neutre, 1 achat)
   - Confirmation multi-timeframe

### 4. Gestion du Risque
- Position size : 2% du capital
- Stop loss : 2% du prix d'entr√©e
- Take profit : 3% du prix d'entr√©e
- Objectif minimum : 25 pips par trade
- Ratio risque/r√©compense : 1:1.5

### 5. Conditions d'Entr√©e
1. Score de confiance ‚â• 70%
2. Confirmation sur au moins 3 timeframes
3. Volume suffisant
4. Volatilit√© dans la plage acceptable
5. Respect des niveaux de risk management

## Fonctionnalit√©s
- ‚ú® Analyse multi-timeframes
- üïí Gestion des gaps temporels
- üîç D√©tection d'anomalies
- üìä Indicateurs techniques
- üíπ Signaux de trading
- ‚öñÔ∏è √âquilibrage des donn√©es
- üîå API Marketstack
- ‚úÖ Validation des donn√©es
- üß™ Tests unitaires

## D√©pendances
```
numpy >= 1.21.0
pandas >= 1.3.0
scikit-learn >= 0.24.2
tensorflow==2.13.0
ta >= 0.7.0
kaggle == 1.5.16
requests == 2.31.0
python-dotenv == 1.0.0
matplotlib >= 3.7.1
seaborn >= 0.12.2
```

## Notes
- üìÖ Donn√©es historiques disponibles de 2004 √† 2024
- üèÜ Optimis√© pour l'or (XAU/USD)
- üìà Minimum 500 √©chantillons requis par timeframe
- ‚ö° Gestion intelligente des gaps temporels
- üîÑ Validation automatique des donn√©es

## Processus lorsque train_initial_model.py est lanc√© 
1. Initialisation
# Configuration initiale
- Cr√©ation des dossiers 'models' et 'logs'
- Configuration du syst√®me de logging
- Initialisation des param√®tres de base

2. Chargement des Donn√©es
# Via HistoricalDataLoader
1. Charge les donn√©es de tous les timeframes (5m, 15m, 30m, etc.)
2. V√©rifie la qualit√© des donn√©es
3. Normalise les formats de dates et colonnes

3. Pr√©traitement (via MLPreprocessor)
  a. Normalisation des donn√©es
   - Prix OHLC
   - Volumes
   
  b. Cr√©ation des features techniques
   - RSI, MACD, Moyennes mobiles
   - Indicateurs de volatilit√©
   - Features personnalis√©es
   
  c. Cr√©ation des s√©quences
   - D√©coupage en s√©quences temporelles
   - Labellisation des donn√©es (-1, 0, 1)
   
  d. Split des donn√©es
   - Train/Validation/Test
   - Stratification pour √©quilibrer les classes
  
4. Optimisation des Hyperparam√®tres
# Via HyperparameterOptimizer
a. D√©finition des plages de param√®tres √† tester
   - Learning rate
   - Taille des batches
   - Unit√©s LSTM
   - Dropout
   - R√©gularisation

b. Utilisation d'Optuna pour l'optimisation
   - Tests de diff√©rentes combinaisons
   - Validation crois√©e temporelle
   - S√©lection des meilleurs param√®tres

5. Construction et Entra√Ænement du Mod√®le
a. Cr√©ation du mod√®le avec les meilleurs param√®tres
   - Architecture LSTM ou Transformer
   - Couches de r√©gularisation
   
b. Entra√Ænement
   - Early stopping
   - R√©duction du learning rate sur plateau
   - Monitoring des performances par classe
   
c. Sauvegarde des checkpoints
   - Meilleur mod√®le
   - Logs d'entra√Ænement

6. √âvaluation et Backtest
a. √âvaluation sur donn√©es de test
   - M√©triques de classification
   - Analyse par timeframe
   
b. Backtest du mod√®le
   - Simulation de trading
   - Calcul des PnL
   - Analyse des performances

7. Sauvegarde des R√©sultats
a. Sauvegarde du mod√®le final
b. Export des m√©triques et statistiques
c. G√©n√©ration des logs d√©taill√©s

## Fonction Principale de train_initial_model.py

Le script `train_initial_model.py` est le c≈ìur du syst√®me d'entra√Ænement du mod√®le de trading. Sa fonction principale est d'entra√Æner un mod√®le LSTM multi-timeframe optimis√© pour la pr√©diction des mouvements de l'or (XAU/USD).

### Caract√©ristiques Cl√©s

1. **Architecture Multi-Timeframe**
   - Analyse simultan√©e de 8 timeframes (5m √† 1M)
   - Fusion des signaux pour une pr√©diction robuste
   - Validation crois√©e temporelle

2. **Optimisation Automatique**
   - Utilisation d'Optuna pour l'optimisation des hyperparam√®tres
   - Recherche sur plus de 20 combinaisons de param√®tres
   - Validation avec walk-forward pour √©viter le surapprentissage

3. **Gestion de la M√©moire**
   - Nettoyage automatique de la m√©moire GPU/CPU
   - Checkpoints r√©guliers
   - Gestion dynamique des ressources

4. **Monitoring Avanc√©**
   - Suivi des performances par classe
   - Ajustement dynamique des poids des classes
   - D√©tection des biais de pr√©diction

5. **Backtest Int√©gr√©**
   - Simulation r√©aliste avec spreads et slippage
   - Calcul des co√ªts dynamiques bas√©s sur l'ATR
   - Gestion sophistiqu√©e du risque

### Processus d'Entra√Ænement

1. **Pr√©paration des Donn√©es**
   ```python
   data_dict = load_historical_data()
   sequences = preprocessor.create_sequences(data_dict)
   ```

2. **Optimisation des Hyperparam√®tres**
   ```python
   best_params = preprocessor.optimize_hyperparameters(
       train_data=sequences['train'],
       n_combinations=20
   )
   ```

3. **Entra√Ænement du Mod√®le**
   ```python
   model = MLModel(input_shape, learning_rate)
   history = model.train_multi_timeframe(
       train_X,
       sequences['train']['y'],
       validation_data=(test_X, sequences['test']['y'])
   )
   ```

4. **Backtest et √âvaluation**
   ```python
   backtest_results = backtest_model(
       model,
       sequences['test']['X'],
       sequences['test']['y'],
       data_dict['5m']
   )
   ```

### Param√®tres Optimis√©s

- Learning rate: 1e-5 √† 1e-2
- Batch size: 16, 32, 64
- Unit√©s LSTM: 32-256 (premi√®re couche), 16-128 (seconde couche)
- Dropout: 0.1-0.5
- R√©gularisation L1/L2: 1e-6 √† 1e-3
- Patience pour early stopping: 10-50

### M√©triques de Performance

- Accuracy balanc√©e par classe
- Ratio de Sharpe
- Maximum drawdown
- Profit factor
- Win rate
- Rendement moyen par trade

## Classe MLModel

La classe `MLModel` est le composant central du syst√®me de trading, impl√©mentant un mod√®le d'apprentissage profond multi-timeframe avec des architectures LSTM et Transformer.

### Caract√©ristiques Principales

1. **Architectures Flexibles**
   - Support LSTM et Transformer
   - S√©lection automatique de l'architecture optimale
   - Configuration adaptative par timeframe

2. **Gestion Multi-Timeframe**
   ```python
   timeframe_config = {
       'input_5m': {'weight': 0.25, 'volatility_factor': 1.0},
       'input_15m': {'weight': 0.20, 'volatility_factor': 1.2},
       'input_1h': {'weight': 0.15, 'volatility_factor': 1.8},
       'input_1d': {'weight': 0.07, 'volatility_factor': 2.5}
   }
   ```

3. **Pr√©diction avec Confiance**
   ```python
   predictions = model.predict_with_confidence(
       X_dict,
       confidence_threshold=0.7
   )
   ```

4. **Optimisation M√©moire**
   - Mode √©conome en m√©moire pour grands datasets
   - Nettoyage automatique des ressources
   - Gestion des batchs optimis√©e

### Architectures Support√©es

1. **LSTM Multi-Timeframe**
   - Couches LSTM empil√©es (32-256 unit√©s)
   - Dropout adaptatif (0.1-0.5)
   - Connexions r√©siduelles

2. **Transformer**
   - Attention multi-t√™te
   - Encodage positionnel
   - Feed-forward networks avec gating

### Fonctionnalit√©s Trading

1. **Calcul des Co√ªts**
   ```python
   costs = model._calculate_transaction_costs(
       price=1800.0,
       volatility=0.002
   )
   ```

2. **Gestion des Positions**
   - Calcul dynamique de la taille
   - Ajustement selon la volatilit√©
   - Gestion des stops et targets

3. **Backtest Int√©gr√©**
   ```python
   results = model.backtest_model(
       X_test_dict,
       y_test,
       confidence_threshold=0.7,
       initial_balance=100000
   )
   ```

### M√©triques et Monitoring

1. **Trading Metrics**
   - Win rate et profit factor
   - Ratio Sharpe et drawdown
   - Analyse des co√ªts de transaction

2. **Performance Monitoring**
   - Suivi par timeframe
   - D√©tection des biais
   - Ajustement des poids

### Gestion des Donn√©es

1. **Normalisation**
   - Standardisation par instrument
   - Gestion des prix hors plage
   - Ajustement dynamique des scalers

2. **Validation**
   - V√©rification des timeframes manquants
   - Interpolation intelligente
   - Gestion des donn√©es incompl√®tes

### Exemple d'Utilisation

```python
# Initialisation
model = MLModel(
    input_shape=(60, 10),
    n_classes=3,
    model_type='auto',
    memory_efficient=True
)

# Entra√Ænement
history = model.train_multi_timeframe(
    X_train,
    y_train,
    validation_data=(X_val, y_val),
    epochs=50
)

# Pr√©diction
predictions = model.predict_with_confidence(
    X_test,
    confidence_threshold=0.7
)

# Backtest
results = model.backtest_model(
    X_test,
    initial_capital=100000
)
```

### Configuration Avanc√©e

1. **Transformer**
   ```python
   transformer_config = {
       'head_size': 256,
       'num_heads': 4,
       'ff_dim_factor': 4,
       'num_blocks': 4
   }
   ```

2. **Optimisation M√©moire**
   ```python
   memory_config = {
       'gru': {
           'units': [64, 32],
           'dropout': 0.3
       }
   }
   ```

3. **Timeframes**
   ```python
   timeframe_keys = {
       '5m': 'input_5m',
       '1h': 'input_1h',
       '1d': 'input_1d'
   }
   ```

Cette classe forme le c≈ìur du syst√®me de trading, combinant apprentissage profond avanc√© et gestion sophistiqu√©e du trading en temps r√©el.

## Classe TechnicalIndicators

La classe `TechnicalIndicators` est responsable du calcul et de la gestion des indicateurs techniques pour l'analyse des prix. Elle offre une approche modulaire et configurable pour l'analyse technique.

### Configuration des Indicateurs

1. **Indicateurs de Tendance**
   ```python
   trend_config = {
       'sma': {
           'periods': [20, 50, 200],
           'apply_to': 'Close'
       },
       'ema': {
           'periods': [12, 26],
           'alpha': None
       },
       'macd': {
           'fast': 12,
           'slow': 26,
           'signal': 9
       },
       'adx': {
           'periods': [14],
           'method': 'wilder'
       }
   }
   ```

2. **Indicateurs de Momentum**
   ```python
   momentum_config = {
       'rsi': {
           'periods': [14],
           'method': 'wilder'
       },
       'stoch': {
           'k_period': 14,
           'd_period': 3,
           'smooth_k': 3
       },
       'williams_r': {
           'period': 14
       }
   }
   ```

3. **Indicateurs de Volatilit√©**
   ```python
   volatility_config = {
       'bbands': {
           'period': 20,
           'std_dev': 2,
           'bands': ['upper', 'middle', 'lower']
       },
       'atr': {
           'periods': [14],
           'normalize': True
       }
   }
   ```

### Fonctionnalit√©s Principales

1. **Calcul Optimis√©**
   - Traitement vectoris√© des donn√©es
   - Gestion intelligente de la m√©moire
   - Parall√©lisation des calculs lourds

2. **Gestion des Donn√©es Manquantes**
   ```python
   # Analyse des s√©quences de NaN
   nan_sequences = indicator._get_nan_sequences(data)
   
   # Interpolation avanc√©e
   clean_data = indicator._advanced_interpolation(data)
   ```

3. **Validation et Nettoyage**
   - D√©tection des anomalies
   - Interpolation intelligente
   - Gestion des valeurs aberrantes

### Utilisation

1. **Initialisation Basique**
   ```python
   indicators = TechnicalIndicators()
   df_with_indicators = indicators.calculate_all(price_data)
   ```

2. **Configuration Personnalis√©e**
   ```python
   custom_config = {
       'trend': {
           'sma': {'periods': [10, 30, 100]},
           'macd': {'fast': 8, 'slow': 21}
       }
   }
   indicators = TechnicalIndicators(custom_config)
   ```

3. **Ajout d'Indicateurs Personnalis√©s**
   ```python
   def custom_indicator(data, params):
       # Logique personnalis√©e
       return result
   
   indicators.add_custom_indicator(
       name='custom_ind',
       function=custom_indicator,
       default_params={'period': 14}
   )
   ```

### Gestion des Erreurs

1. **Validation des Donn√©es**
   - V√©rification des formats
   - Contr√¥le des plages de valeurs
   - D√©tection des discontinuit√©s

2. **Nettoyage par Cat√©gorie**
   - Approche sp√©cifique par type d'indicateur
   - M√©thodes d'interpolation adapt√©es
   - Gestion des cas limites

3. **Logging Avanc√©**
   ```python
   indicators._log_indicator_stats(df)
   # Affiche des statistiques d√©taill√©es par indicateur
   ```

### Optimisations

1. **Traitement des S√©quences**
   - D√©tection intelligente des gaps
   - Interpolation contextuelle
   - Pr√©servation des tendances

2. **Performance**
   - Mise en cache des calculs interm√©diaires
   - Optimisation des allocations m√©moire
   - Parall√©lisation quand possible

3. **Qualit√© des Donn√©es**
   - Validation multi-niveau
   - Correction automatique des anomalies
   - Maintien de la coh√©rence temporelle

### Exemple Complet

```python
# Configuration personnalis√©e
config = {
    'trend': {
        'sma': {'periods': [20, 50, 200]},
        'ema': {'periods': [12, 26]}
    },
    'momentum': {
        'rsi': {'periods': [14]},
        'stoch': {'k_period': 14}
    },
    'volatility': {
        'bbands': {'period': 20},
        'atr': {'periods': [14]}
    }
}

# Initialisation
indicators = TechnicalIndicators(config)

# Calcul des indicateurs
df_processed = indicators.calculate_all(
    df=price_data,
    instrument='XAUUSD'
)

# Validation et nettoyage
df_clean = indicators._validate_and_clean(df_processed)

# Log des statistiques
indicators._log_indicator_stats(df_clean)
```

Cette classe fournit une base solide pour l'analyse technique, avec une emphase sur la qualit√© des donn√©es et la performance des calculs.

## Classe MLPreprocessor

La classe `MLPreprocessor` est responsable du pr√©traitement des donn√©es pour le mod√®le de machine learning. Elle g√®re la normalisation, le calcul des features et la pr√©paration des s√©quences d'entra√Ænement.

### Caract√©ristiques Principales

1. **Normalisation Sp√©cialis√©e**
   ```python
   class MLPreprocessor:
       def __init__(self, instrument='XAUUSD'):
           self.feature_scaler = MinMaxScaler()  # Features techniques
           self.price_scaler = MinMaxScaler()    # Prix OHLC
           self.expected_price_ranges = {
               'XAUUSD': {
                   'min': 1000,
                   'max': 3000,
                   'unit': 'USD/oz'
               }
           }
   ```

2. **Gestion Multi-Timeframe**
   - Traitement parall√®le des timeframes
   - Synchronisation des donn√©es
   - Validation crois√©e des features

3. **Calcul des Features**
   - Indicateurs techniques via TechnicalIndicators
   - Features d√©riv√©es des prix
   - Normalisation adaptative

### Pr√©paration des Donn√©es

1. **Pr√©traitement Multi-Timeframe**
   ```python
   processed_data = preprocessor.prepare_multi_timeframe_features(
       data_dict={
           '5m': df_5m,
           '1h': df_1h,
           '1d': df_1d
       }
   )
   ```

2. **Cr√©ation des S√©quences**
   ```python
   X_train, y_train, X_test, y_test = preprocessor.prepare_data_for_training(
       data_dict=processed_data,
       sequence_length=15,
       prediction_horizon=12,
       train_size=0.8
   )
   ```

3. **Validation des Donn√©es**
   - V√©rification des distributions
   - D√©tection des anomalies
   - Gestion des valeurs manquantes

### Features Techniques

1. **Indicateurs de Base**
   ```python
   def _add_basic_indicators(self, df):
       # SMA
       df['SMA_20'] = df['Close'].rolling(window=20).mean()
       
       # RSI
       df['RSI'] = self._calculate_rsi(df['Close'])
       
       # Volatilit√©
       df['Volatility'] = df['Close'].pct_change().rolling(20).std()
       
       return df
   ```

2. **Features Avanc√©es**
   - ATR et Bandes de Bollinger
   - Returns et volatilit√©
   - Features personnalis√©es

3. **Normalisation Adaptative**
   - Standardisation par instrument
   - Gestion des outliers
   - Mise √† l'√©chelle dynamique

### Pr√©paration Live

1. **Features Temps R√©el**
   ```python
   live_features = preprocessor._prepare_live_features(
       new_data=latest_data,
       timeframe='5m'
   )
   ```

2. **Mise √† Jour Continue**
   - Actualisation des scalers
   - Gestion de la m√©moire
   - Validation en temps r√©el

### Logging et Monitoring

1. **Statistiques D√©taill√©es**
   ```python
   preprocessor._print_distribution(y_train)
   # Affiche:
   # Distribution des classes:
   # Classe -1:  985 √©chantillons (32.83%)
   # Classe  0: 1024 √©chantillons (34.13%)
   # Classe  1:  991 √©chantillons (33.03%)
   ```

2. **Validation des Features**
   - Contr√¥le des distributions
   - D√©tection des biais
   - Suivi des transformations

### Exemple d'Utilisation Complet

```python
# Initialisation
preprocessor = MLPreprocessor(instrument='XAUUSD')

# Chargement et pr√©traitement des donn√©es
data_dict = load_historical_data()
processed_data = preprocessor.prepare_multi_timeframe_features(data_dict)

# V√©rification des features
for timeframe, data in processed_data.items():
    print(f"\nTimeframe: {timeframe}")
    print(f"Shape: {data.shape}")
    print("\nFeatures calcul√©es:")
    print(data.columns.tolist())

# Pr√©paration pour l'entra√Ænement
X_train, y_train, X_test, y_test = preprocessor.prepare_data_for_training(
    data_dict=processed_data,
    sequence_length=15,
    prediction_horizon=12
)

# Validation des distributions
preprocessor._print_distribution(y_train)
preprocessor._print_distribution(y_test)
```

### Configuration Avanc√©e

1. **Param√®tres de Pr√©traitement**
   ```python
   config = {
       'sequence_length': 15,
       'prediction_horizon': 12,
       'train_size': 0.8,
       'target_samples': 3000
   }
   ```

2. **Gestion des Timeframes**
   ```python
   timeframe_weights = {
       '5m': 0.25,
       '15m': 0.20,
       '1h': 0.15,
       '4h': 0.10
   }
   ```

3. **Validation des Donn√©es**
   ```python
   validation_params = {
       'min_samples': 500,
       'max_gap': 20,
       'distribution_threshold': 0.1
   }
   ```

Cette classe est essentielle pour la pr√©paration des donn√©es d'entra√Ænement et assure la qualit√© et la coh√©rence des features utilis√©es par le mod√®le.

## Classe DataProcessor

La classe `DataProcessor` est responsable du traitement et du nettoyage des donn√©es financi√®res brutes. Elle h√©rite de `BaseDataProcessor` et impl√©mente une logique sp√©cialis√©e pour diff√©rents types d'instruments.

### Architecture

1. **Hi√©rarchie des Classes**
   ```python
   class BaseDataProcessor(ABC):
       """Classe de base abstraite pour le traitement des donn√©es"""
       
   class DataProcessor(BaseDataProcessor):
       """Processeur g√©n√©rique pour les donn√©es financi√®res"""
       
       def __init__(self, instrument_type='forex', is_base=False):
           self.instrument_type = instrument_type
           self.processor = None if is_base else self._get_specialized_processor()
   ```

2. **Configuration par Timeframe**
   ```python
   gap_thresholds = {
       '5m':  {'max_gap_ratio': 0.05, 'critical_ratio': 1.5},
       '15m': {'max_gap_ratio': 0.07, 'critical_ratio': 2.0},
       '1h':  {'max_gap_ratio': 0.10, 'critical_ratio': 3.0},
       '1d':  {'max_gap_ratio': 0.15, 'critical_ratio': 5.0}
   }
   ```

### Fonctionnalit√©s Principales

1. **Traitement des Donn√©es Manquantes**
   ```python
   def _handle_missing_data(self, df, timeframe):
       # Traitement des prix OHLC
       if any(df[price_cols].isna().any()):
           df = self._handle_price_gaps(df, timeframe)
           
       # Traitement du volume
       if df['Volume'].isna().any():
           df = self._handle_volume_gaps(df, timeframe)
           
       return df
   ```

2. **Traitement par Chunks**
   ```python
   chunk_config = {
       '5m':  {'size': 50000, 'overlap': 1000},
       '15m': {'size': 25000, 'overlap': 500},
       '1h':  {'size': 10000, 'overlap': 200}
   }
   ```

3. **Validation des Donn√©es**
   - V√©rification de la continuit√© temporelle
   - D√©tection des anomalies de prix
   - Validation des volumes

### Gestion des Gaps

1. **D√©tection des Gaps**
   ```python
   def detect_gaps(self, df, timeframe):
       # Identifier les gaps de prix
       price_gaps = df[price_cols].isna().all(axis=1)
       isolated_gaps = ~price_gaps.shift(1) & price_gaps & ~price_gaps.shift(-1)
       long_gaps = price_gaps & ~isolated_gaps
   ```

2. **Interpolation Adaptative**
   - Interpolation lin√©aire pour gaps courts
   - Interpolation cubique pour gaps moyens
   - M√©thodes avanc√©es pour longs gaps

3. **Fusion des Chunks**
   ```python
   def _merge_overlap(self, prev_chunk, curr_chunk, overlap):
       # Fusion progressive des valeurs
       weights = np.linspace(0, 1, overlap)
       overlap_mask = get_overlap_mask(curr_chunk, overlap)
       
       for col in numeric_cols:
           curr_chunk.loc[overlap_mask, col] = weighted_merge(
               prev_vals=prev_chunk.loc[overlap_mask, col],
               curr_vals=curr_chunk.loc[overlap_mask, col],
               weights=weights
           )
   ```

### Indicateurs Techniques

1. **Configuration de Base**
   ```python
   technical_indicators_config = {
       'trend': {
           'EMA': {'periods': [12, 26, 50]},
           'MACD': {'fast': 12, 'slow': 26, 'signal': 9}
       }
   }
   ```

2. **Ajout d'Indicateurs**
   ```python
   def add_technical_indicators(self, df):
       try:
           self.logger.info("\nAjout des indicateurs techniques...")
           return self.indicator_calculator.calculate_all(df)
       except Exception as e:
           return self._add_basic_indicators(df)
   ```

### Logging et Monitoring

1. **Configuration du Logging**
   ```python
   def _setup_logging(self):
       logger = logging.getLogger(self.__class__.__name__)
       fh = logging.FileHandler(
           f'logs/preprocessing/processor_{datetime.now():%Y%m%d_%H%M%S}.log',
           encoding='utf-8'
       )
   ```

2. **Suivi des Op√©rations**
   - Logging d√©taill√© des transformations
   - Statistiques de nettoyage
   - Alertes sur anomalies

### Exemple d'Utilisation

```python
# Initialisation
processor = DataProcessor(instrument_type='forex')

# Chargement et traitement des donn√©es
df = load_raw_data('XAUUSD_5m.csv')
df_processed = processor.process_data(
    df,
    timeframe='5m',
    handle_gaps=True,
    add_indicators=True
)

# V√©rification des r√©sultats
processor.validate_processed_data(df_processed)
```

### Configuration Avanc√©e

1. **Param√®tres de Traitement**
   ```python
   processing_params = {
       'gap_filling': {
           'max_gap_length': 5,
           'interpolation_method': 'cubic'
       },
       'chunking': {
           'enable': True,
           'chunk_size': 50000
       },
       'validation': {
           'price_threshold': 3.0,
           'volume_threshold': 5.0
       }
   }
   ```

2. **Gestion des Erreurs**
   ```python
   try:
       df_processed = processor.process_data(df)
   except DataQualityError as e:
       logger.error(f"Erreur de qualit√© des donn√©es: {e}")
       df_processed = processor.apply_fallback_processing(df)
   ```

Cette classe forme la base du pipeline de pr√©traitement des donn√©es, assurant leur qualit√© et leur coh√©rence avant l'utilisation par les mod√®les de ML.

## Classe GoldPricePredictor

La classe `GoldPricePredictor` impl√©mente un mod√®le de deep learning sp√©cialis√© pour la pr√©diction des prix de l'or, utilisant une architecture multi-timeframe avec attention.

### Architecture du Mod√®le

1. **Structure Multi-Timeframe**
   ```python
   def __init__(self, sequence_length=10, n_features=29):
       # Entr√©es pour chaque timeframe
       input_1d = Input(shape=(sequence_length, n_features))
       input_4h = Input(shape=(sequence_length * 6, n_features))
       input_1h = Input(shape=(sequence_length * 24, n_features))
   ```

2. **Branches de Traitement**
   ```python
   def create_timeframe_branch(inputs, name):
       # Convolutions 1D
       x = Conv1D(32, kernel_size=2, activation='relu')(inputs)
       x = Conv1D(32, kernel_size=4, activation='relu')(x)
       
       # BiLSTM avec attention
       lstm = Bidirectional(LSTM(32, return_sequences=True))(x)
       attention = Attention()([lstm, lstm])
       
       return attention
   ```

### Caract√©ristiques Principales

1. **Architecture Avanc√©e**
   - Convolutions 1D pour l'extraction de features
   - BiLSTM avec m√©canisme d'attention
   - Connexions r√©siduelles
   - Normalisation des couches

2. **Loss Function Adaptative**
   ```python
   def multi_timeframe_loss(y_true, y_pred):
       # MSE de base
       mse = tf.square(y_pred - y_true)
       
       # Variations √† diff√©rentes √©chelles
       variations = [
           calculate_variation(y_true, 1),   # Daily
           calculate_variation(y_true, 6),   # 4h
           calculate_variation(y_true, 24)   # 1h
       ]
       
       # Poids adaptatifs
       weights = [tf.where(tf.abs(var) > 0.01, 1.5, 1.0)
                 for var in variations]
   ```

3. **Learning Rate Scheduling**
   ```python
   def create_lr_scheduler(self, epochs):
       initial_learning_rate = 0.0003
       decay_steps = epochs * 0.5
       decay_rate = 0.2
       
       def lr_scheduler(epoch):
           if epoch < decay_steps:
               return initial_learning_rate
           else:
               return initial_learning_rate * (
                   decay_rate ** ((epoch - decay_steps) / 10)
               )
   ```

### Entra√Ænement et √âvaluation

1. **Configuration de l'Entra√Ænement**
   ```python
   model.train(
       X_train,
       y_train,
       epochs=150,
       batch_size=32,
       validation_split=0.2,
       callbacks=[
           early_stopping,
           lr_scheduler,
           checkpoint
       ]
   )
   ```

2. **Callbacks Avanc√©s**
   - Early stopping avec restauration des meilleurs poids
   - Learning rate adaptatif
   - Checkpointing des mod√®les

3. **Visualisation des Performances**
   ```python
   def plot_training_history(self, history):
       plt.figure(figsize=(12, 4))
       
       # Loss plot
       plt.subplot(1, 2, 1)
       plt.plot(history.history['loss'])
       plt.plot(history.history['val_loss'])
       
       # MAE plot
       plt.subplot(1, 2, 2)
       plt.plot(history.history['mae'])
       plt.plot(history.history['val_mae'])
   ```

### Pr√©diction et Inf√©rence

1. **Format Multi-Timeframe**
   ```python
   def predict(self, X_test):
       X_test_dict = {
           'daily_input': X_test,
           '4h_input': np.repeat(X_test, 6, axis=1),
           '1h_input': np.repeat(X_test, 24, axis=1)
       }
       return self.model.predict(X_test_dict)
   ```

2. **M√©triques d'√âvaluation**
   ```python
   def evaluate(self, y_true, y_pred):
       return {
           'MSE': mean_squared_error(y_true, y_pred),
           'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
           'MAE': mean_absolute_error(y_true, y_pred)
       }
   ```

### Exemple d'Utilisation

```python
# Initialisation
predictor = GoldPricePredictor(
    sequence_length=10,
    n_features=29
)

# Entra√Ænement
history = predictor.train(
    X_train,
    y_train,
    epochs=150,
    batch_size=32
)

# Pr√©diction
predictions = predictor.predict(X_test)

# √âvaluation
metrics = predictor.evaluate(y_test, predictions)
print(f"RMSE: {metrics['RMSE']:.4f}")
print(f"MAE: {metrics['MAE']:.4f}")
```

### Configuration Avanc√©e

1. **Param√®tres du Mod√®le**
   ```python
   model_config = {
       'conv_filters': [32, 32],
       'lstm_units': [32, 64],
       'dense_units': [32, 16],
       'dropout_rate': 0.15,
       'learning_rate': 0.001
   }
   ```

2. **Param√®tres d'Entra√Ænement**
   ```python
   training_config = {
       'batch_size': 32,
       'epochs': 150,
       'validation_split': 0.2,
       'early_stopping_patience': 15
   }
   ```

Cette classe constitue le c≈ìur du syst√®me de pr√©diction, combinant une architecture sophistiqu√©e avec des m√©canismes d'attention pour capturer les d√©pendances temporelles √† diff√©rentes √©chelles.

## Flux d'Ex√©cution de train_initial_model.py

### Vue d'Ensemble
```mermaid
graph TD
    A[train_initial_model.py] --> B[HistoricalDataLoader]
    A --> C[MLPreprocessor]
    A --> D[MLModel]
    C --> E[TechnicalIndicators]
    C --> F[DataProcessor]
    D --> G[GoldPricePredictor]
```

### S√©quence d'Ex√©cution

1. **Initialisation (train_initial_model.py)**
   - Configure le logging et les dossiers
   - Initialise les param√®tres d'entra√Ænement

2. **Collecte des Donn√©es**
   ```python
   # Via historical_data.py
   loader = HistoricalDataLoader()
   data = loader.load_all_timeframes()  # Charge 5m -> 1M
   ```

3. **Pr√©traitement**
   ```python
   # Cascade de traitement
   preprocessor = MLPreprocessor()
   data_processor = DataProcessor()  # Nettoyage basique
   technical_indicators = TechnicalIndicators()  # Calcul des indicateurs
   
   processed_data = preprocessor.prepare_data(data)
   ```

4. **Construction du Mod√®le**
   ```python
   # Utilise price_predictor.py et ml_model.py
   model = MLModel()
   predictor = GoldPricePredictor()
   ```

### Interactions Cl√©s

- **MLPreprocessor** orchestre le pr√©traitement en utilisant:
  - DataProcessor pour le nettoyage
  - TechnicalIndicators pour les features
  - Gestion des s√©quences multi-timeframes

- **MLModel** coordonne la pr√©diction via:
  - GoldPricePredictor pour l'architecture neuronale
  - Gestion des backtests et m√©triques

### Fichiers Impliqu√©s

- `train_initial_model.py` : Script principal
- `historical_data.py` : Collecte des donn√©es
- `ml_preprocessor.py` : Coordination du pr√©traitement
- `technical_indicators.py` : Calcul des indicateurs
- `data_processor.py` : Nettoyage des donn√©es
- `ml_model.py` : Gestion du mod√®le
- `price_predictor.py` : Architecture neuronale

Cette orchestration assure un pipeline fluide du chargement des donn√©es jusqu'√† l'entra√Ænement du mod√®le.

